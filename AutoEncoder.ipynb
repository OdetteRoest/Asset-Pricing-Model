{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/odetteroest/Documents/GitHub/Asset-Pricing-Model/AutoEncoder.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/odetteroest/Documents/GitHub/Asset-Pricing-Model/AutoEncoder.ipynb#ch0000001?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mC:/.../AutoEncoder/nyse/clean_data.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/.../AutoEncoder/nyse/clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/odetteroest/Documents/GitHub/Asset-Pricing-Model/AutoEncoder.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/odetteroest/Documents/GitHub/Asset-Pricing-Model/AutoEncoder.ipynb#ch0000002?line=0'>1</a>\u001b[0m data\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_df(df):\n",
    "        \n",
    "    for col in list(df.columns):\n",
    "       \n",
    "        mean, std = df[col].mean(), df[col].std()\n",
    "\n",
    "        df.loc[:, col] = (df[col] -mean) /(std + 1)   \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns</th>\n",
       "      <th>month spead</th>\n",
       "      <th>high off close</th>\n",
       "      <th>low off close</th>\n",
       "      <th>high of open</th>\n",
       "      <th>low off open</th>\n",
       "      <th>volume</th>\n",
       "      <th>Accounts Payable</th>\n",
       "      <th>Accounts Receivable</th>\n",
       "      <th>Add'l income/expense items</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Total Current Assets</th>\n",
       "      <th>Total Current Liabilities</th>\n",
       "      <th>Total Equity</th>\n",
       "      <th>Total Liabilities</th>\n",
       "      <th>Total Liabilities &amp; Equity</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Treasury Stock</th>\n",
       "      <th>Earnings Per Share</th>\n",
       "      <th>Estimated Shares Outstanding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017750</td>\n",
       "      <td>-0.237354</td>\n",
       "      <td>-0.006863</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>-0.008552</td>\n",
       "      <td>-0.008242</td>\n",
       "      <td>0.849448</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.204119</td>\n",
       "      <td>-1.525988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097916</td>\n",
       "      <td>0.371524</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>-0.259769</td>\n",
       "      <td>-0.072938</td>\n",
       "      <td>-0.097857</td>\n",
       "      <td>0.744223</td>\n",
       "      <td>0.299171</td>\n",
       "      <td>1.112200</td>\n",
       "      <td>0.131225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040972</td>\n",
       "      <td>-0.241399</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.005288</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.680497</td>\n",
       "      <td>0.227325</td>\n",
       "      <td>-0.801420</td>\n",
       "      <td>-0.535363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078480</td>\n",
       "      <td>0.945065</td>\n",
       "      <td>0.675777</td>\n",
       "      <td>-0.315340</td>\n",
       "      <td>-0.043053</td>\n",
       "      <td>-0.078421</td>\n",
       "      <td>0.145670</td>\n",
       "      <td>-0.205239</td>\n",
       "      <td>0.056006</td>\n",
       "      <td>1.244848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026131</td>\n",
       "      <td>-0.293996</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>-0.005736</td>\n",
       "      <td>-0.000769</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.271597</td>\n",
       "      <td>0.044816</td>\n",
       "      <td>-0.164156</td>\n",
       "      <td>0.816387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127973</td>\n",
       "      <td>0.749414</td>\n",
       "      <td>0.494109</td>\n",
       "      <td>0.252412</td>\n",
       "      <td>-0.180401</td>\n",
       "      <td>-0.127914</td>\n",
       "      <td>0.064657</td>\n",
       "      <td>-0.306989</td>\n",
       "      <td>0.029089</td>\n",
       "      <td>1.096431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036966</td>\n",
       "      <td>-0.354683</td>\n",
       "      <td>-0.006072</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>-0.088412</td>\n",
       "      <td>0.551902</td>\n",
       "      <td>0.599153</td>\n",
       "      <td>0.644705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132544</td>\n",
       "      <td>1.444840</td>\n",
       "      <td>0.953489</td>\n",
       "      <td>0.143504</td>\n",
       "      <td>-0.169978</td>\n",
       "      <td>-0.132551</td>\n",
       "      <td>1.626057</td>\n",
       "      <td>0.299171</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>0.073823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003353</td>\n",
       "      <td>1.441696</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>-0.583390</td>\n",
       "      <td>-0.261929</td>\n",
       "      <td>-0.037895</td>\n",
       "      <td>-0.128851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206913</td>\n",
       "      <td>0.939303</td>\n",
       "      <td>0.198375</td>\n",
       "      <td>-0.378967</td>\n",
       "      <td>-0.178625</td>\n",
       "      <td>-0.206852</td>\n",
       "      <td>-0.396373</td>\n",
       "      <td>0.075051</td>\n",
       "      <td>0.794317</td>\n",
       "      <td>-0.562624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    returns  month spead  high off close  low off close  high of open  \\\n",
       "0  0.017750    -0.237354       -0.006863       0.006334     -0.008552   \n",
       "1  0.040972    -0.241399       -0.000543      -0.005288     -0.002151   \n",
       "2  0.026131    -0.293996        0.000905      -0.005736     -0.000769   \n",
       "3  0.036966    -0.354683       -0.006072       0.000282     -0.002278   \n",
       "4 -0.003353     1.441696       -0.000196      -0.000312      0.006551   \n",
       "\n",
       "   low off open    volume  Accounts Payable  Accounts Receivable  \\\n",
       "0     -0.008242  0.849448          0.006673             0.204119   \n",
       "1      0.003596  0.680497          0.227325            -0.801420   \n",
       "2      0.003984  0.271597          0.044816            -0.164156   \n",
       "3      0.003452 -0.088412          0.551902             0.599153   \n",
       "4      0.007116 -0.583390         -0.261929            -0.037895   \n",
       "\n",
       "   Add'l income/expense items  ...  Total Assets  Total Current Assets  \\\n",
       "0                   -1.525988  ...     -0.097916              0.371524   \n",
       "1                   -0.535363  ...     -0.078480              0.945065   \n",
       "2                    0.816387  ...     -0.127973              0.749414   \n",
       "3                    0.644705  ...     -0.132544              1.444840   \n",
       "4                   -0.128851  ...     -0.206913              0.939303   \n",
       "\n",
       "   Total Current Liabilities  Total Equity  Total Liabilities  \\\n",
       "0                   0.964126     -0.259769          -0.072938   \n",
       "1                   0.675777     -0.315340          -0.043053   \n",
       "2                   0.494109      0.252412          -0.180401   \n",
       "3                   0.953489      0.143504          -0.169978   \n",
       "4                   0.198375     -0.378967          -0.178625   \n",
       "\n",
       "   Total Liabilities & Equity  Total Revenue  Treasury Stock  \\\n",
       "0                   -0.097857       0.744223        0.299171   \n",
       "1                   -0.078421       0.145670       -0.205239   \n",
       "2                   -0.127914       0.064657       -0.306989   \n",
       "3                   -0.132551       1.626057        0.299171   \n",
       "4                   -0.206852      -0.396373        0.075051   \n",
       "\n",
       "   Earnings Per Share  Estimated Shares Outstanding  \n",
       "0            1.112200                      0.131225  \n",
       "1            0.056006                      1.244848  \n",
       "2            0.029089                      1.096431  \n",
       "3            0.035498                      0.073823  \n",
       "4            0.794317                     -0.562624  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_df(data.iloc[:,2:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 317)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = df.returns.to_numpy()\n",
    "x = x_input.reshape(1, len(df.returns))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 81)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,1:].to_numpy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factors(\n",
      "  (fc1): Linear(in_features=317, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=81, bias=True)\n",
      "  (fc3): Linear(in_features=25677, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=25677, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Factors(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(Factors, self).__init__()\n",
    "        #encoder \n",
    "        self.fc1 = nn.Linear(no_of_stocks, encoding_dim)\n",
    "        \n",
    "        #decoder \n",
    "        self.fc2 = nn.Linear(encoding_dim, no_of_metrics)\n",
    "        \n",
    "        #encoder  \n",
    "        self.fc3 = nn.Linear(no_of_metrics_flat, encoding_dim)\n",
    "        \n",
    "        #decoder\n",
    "        self.fc4 = nn.Linear(encoding_dim, no_of_metrics_flat)\n",
    "        \n",
    "\n",
    "    def forward(self, x, y):\n",
    "       \n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = (self.fc2(x))\n",
    "        \n",
    "        y = torch.flatten(y)\n",
    "        \n",
    "        y = F.relu(self.fc3(y))\n",
    "        \n",
    "        y = F.relu(self.fc4(y))\n",
    "        \n",
    "        y = y.view(no_of_metrics, no_of_stocks)\n",
    "        x = x.view(1,no_of_metrics)\n",
    "        \n",
    "        w = torch.mm(x, y)\n",
    "        \n",
    "        return w\n",
    "\n",
    "# initialize the NN\n",
    "no_of_stocks = 317 #len(df.returns)\n",
    "no_of_metrics = 81\n",
    "no_of_metrics_flat = no_of_stocks * no_of_metrics  #metrics.shape[1] \n",
    "encoding_dim = 32\n",
    "\n",
    "model = Factors(encoding_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0 \n",
    "x_batch = no_of_stocks\n",
    "y_batch = no_of_stocks\n",
    "x_loader = torch.utils.data.DataLoader(x, batch_size=x_batch, num_workers=num_workers)\n",
    "y_loader = torch.utils.data.DataLoader(y, batch_size=y_batch, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.032876\n",
      "Epoch: 2 \tTraining Loss: 1.403714\n",
      "Epoch: 3 \tTraining Loss: 0.085510\n",
      "Epoch: 4 \tTraining Loss: 0.006720\n",
      "Epoch: 5 \tTraining Loss: 0.006307\n",
      "Epoch: 6 \tTraining Loss: 0.005961\n",
      "Epoch: 7 \tTraining Loss: 0.005667\n",
      "Epoch: 8 \tTraining Loss: 0.005406\n",
      "Epoch: 9 \tTraining Loss: 0.005176\n",
      "Epoch: 10 \tTraining Loss: 0.004966\n",
      "Epoch: 11 \tTraining Loss: 0.004771\n",
      "Epoch: 12 \tTraining Loss: 0.004590\n",
      "Epoch: 13 \tTraining Loss: 0.004420\n",
      "Epoch: 14 \tTraining Loss: 0.004259\n",
      "Epoch: 15 \tTraining Loss: 0.004106\n",
      "Epoch: 16 \tTraining Loss: 0.003960\n",
      "Epoch: 17 \tTraining Loss: 0.003819\n",
      "Epoch: 18 \tTraining Loss: 0.003682\n",
      "Epoch: 19 \tTraining Loss: 0.003550\n",
      "Epoch: 20 \tTraining Loss: 0.003421\n",
      "Epoch: 21 \tTraining Loss: 0.003295\n",
      "Epoch: 22 \tTraining Loss: 0.003173\n",
      "Epoch: 23 \tTraining Loss: 0.003053\n",
      "Epoch: 24 \tTraining Loss: 0.002936\n",
      "Epoch: 25 \tTraining Loss: 0.002822\n",
      "Epoch: 26 \tTraining Loss: 0.002710\n",
      "Epoch: 27 \tTraining Loss: 0.002602\n",
      "Epoch: 28 \tTraining Loss: 0.002497\n",
      "Epoch: 29 \tTraining Loss: 0.002395\n",
      "Epoch: 30 \tTraining Loss: 0.002297\n",
      "Epoch: 31 \tTraining Loss: 0.002201\n",
      "Epoch: 32 \tTraining Loss: 0.002109\n",
      "Epoch: 33 \tTraining Loss: 0.002019\n",
      "Epoch: 34 \tTraining Loss: 0.001934\n",
      "Epoch: 35 \tTraining Loss: 0.001851\n",
      "Epoch: 36 \tTraining Loss: 0.001772\n",
      "Epoch: 37 \tTraining Loss: 0.001697\n",
      "Epoch: 38 \tTraining Loss: 0.001624\n",
      "Epoch: 39 \tTraining Loss: 0.001555\n",
      "Epoch: 40 \tTraining Loss: 0.001489\n",
      "Epoch: 41 \tTraining Loss: 0.001426\n",
      "Epoch: 42 \tTraining Loss: 0.001365\n",
      "Epoch: 43 \tTraining Loss: 0.001308\n",
      "Epoch: 44 \tTraining Loss: 0.001253\n",
      "Epoch: 45 \tTraining Loss: 0.001201\n",
      "Epoch: 46 \tTraining Loss: 0.001151\n",
      "Epoch: 47 \tTraining Loss: 0.001103\n",
      "Epoch: 48 \tTraining Loss: 0.001058\n",
      "Epoch: 49 \tTraining Loss: 0.001015\n",
      "Epoch: 50 \tTraining Loss: 0.000974\n",
      "Epoch: 51 \tTraining Loss: 0.000934\n",
      "Epoch: 52 \tTraining Loss: 0.000897\n",
      "Epoch: 53 \tTraining Loss: 0.000861\n",
      "Epoch: 54 \tTraining Loss: 0.000827\n",
      "Epoch: 55 \tTraining Loss: 0.000795\n",
      "Epoch: 56 \tTraining Loss: 0.000764\n",
      "Epoch: 57 \tTraining Loss: 0.000734\n",
      "Epoch: 58 \tTraining Loss: 0.000706\n",
      "Epoch: 59 \tTraining Loss: 0.000679\n",
      "Epoch: 60 \tTraining Loss: 0.000653\n",
      "Epoch: 61 \tTraining Loss: 0.000629\n",
      "Epoch: 62 \tTraining Loss: 0.000606\n",
      "Epoch: 63 \tTraining Loss: 0.000583\n",
      "Epoch: 64 \tTraining Loss: 0.000562\n",
      "Epoch: 65 \tTraining Loss: 0.000541\n",
      "Epoch: 66 \tTraining Loss: 0.000522\n",
      "Epoch: 67 \tTraining Loss: 0.000503\n",
      "Epoch: 68 \tTraining Loss: 0.000485\n",
      "Epoch: 69 \tTraining Loss: 0.000467\n",
      "Epoch: 70 \tTraining Loss: 0.000451\n",
      "Epoch: 71 \tTraining Loss: 0.000434\n",
      "Epoch: 72 \tTraining Loss: 0.000419\n",
      "Epoch: 73 \tTraining Loss: 0.000404\n",
      "Epoch: 74 \tTraining Loss: 0.000390\n",
      "Epoch: 75 \tTraining Loss: 0.000376\n",
      "Epoch: 76 \tTraining Loss: 0.000363\n",
      "Epoch: 77 \tTraining Loss: 0.000350\n",
      "Epoch: 78 \tTraining Loss: 0.000338\n",
      "Epoch: 79 \tTraining Loss: 0.000327\n",
      "Epoch: 80 \tTraining Loss: 0.000315\n",
      "Epoch: 81 \tTraining Loss: 0.000305\n",
      "Epoch: 82 \tTraining Loss: 0.000294\n",
      "Epoch: 83 \tTraining Loss: 0.000284\n",
      "Epoch: 84 \tTraining Loss: 0.000275\n",
      "Epoch: 85 \tTraining Loss: 0.000266\n",
      "Epoch: 86 \tTraining Loss: 0.000257\n",
      "Epoch: 87 \tTraining Loss: 0.000248\n",
      "Epoch: 88 \tTraining Loss: 0.000240\n",
      "Epoch: 89 \tTraining Loss: 0.000232\n",
      "Epoch: 90 \tTraining Loss: 0.000225\n",
      "Epoch: 91 \tTraining Loss: 0.000218\n",
      "Epoch: 92 \tTraining Loss: 0.000211\n",
      "Epoch: 93 \tTraining Loss: 0.000204\n",
      "Epoch: 94 \tTraining Loss: 0.000197\n",
      "Epoch: 95 \tTraining Loss: 0.000191\n",
      "Epoch: 96 \tTraining Loss: 0.000185\n",
      "Epoch: 97 \tTraining Loss: 0.000179\n",
      "Epoch: 98 \tTraining Loss: 0.000174\n",
      "Epoch: 99 \tTraining Loss: 0.000168\n",
      "Epoch: 100 \tTraining Loss: 0.000163\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for x, y in zip(x_loader, y_loader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(x.float(), y.float())\n",
    "        # calculate the loss\n",
    "        \n",
    "        loss = criterion(outputs, x.float())\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()\n",
    "            \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(x_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.021036\n",
       "1    0.003728\n",
       "2   -0.012099\n",
       "3   -0.000545\n",
       "4   -0.043540\n",
       "Name: returns, dtype: float64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.returns.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02137146  0.00388982 -0.01229126 -0.0003422  -0.0432324 ]\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(x_loader, y_loader):\n",
    "    result = model(x.float(), y.float())\n",
    "    \n",
    "    unnormal_result = result * (data.returns.std() + 1) + data.returns.mean()\n",
    "    \n",
    "    print(unnormal_result.detach().numpy()[0,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
